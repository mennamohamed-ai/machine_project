# ุดุฑุญ ููุงููู ุงูุชูููู ูุงูููุฐุฌุฉ ูู ูุดุฑูุน Bank Loan

ุดุฑุญ ุชูุตููู ููููุงููู ุงูุฃุณุงุณูุฉ ุงููุณุชุฎุฏูุฉ ูู ุชูููู ููุงุฐุฌ ุงูุชุนูู ุงูุขูู.

---

## ๐ ููุฑุณ ุงููุญุชููุงุช

1. [Linear Regression](#linear-regression)
2. [KNN Regression](#knn-regression)
3. [Learning Curve](#learning-curve)
4. [Validation Curve](#validation-curve)
5. [Confusion Matrix](#confusion-matrix)
6. [ROC Curve ู AUC](#roc-curve-ู-auc)
7. [Accuracy](#accuracy)
8. [ููุงุฑูุฉ ุงูููุงุฐุฌ](#ููุงุฑูุฉ-ุงูููุงุฐุฌ)

---

## ๐ค Linear Regression

### ูุง ูู Linear Regressionุ

**ุงูุงูุญุฏุงุฑ ุงูุฎุทู** ูู ูููุฐุฌ ุฑูุงุถู ุจุณูุท ูุญุงูู ุฅูุฌุงุฏ ุฎุท ูุณุชููู ููุฑ ุจุงูุจูุงูุงุช ุจุฃูุถู ุทุฑููุฉ.

### ุงููุนุงุฏูุฉ

```
y = wโxโ + wโxโ + wโxโ + ... + wโxโ + b
```

ุญูุซ:
- **y**: ุงููููุฉ ุงููุชูุจุฃ ุจูุง (ูู ููุจู ุงููุฑุถุ ูุนู/ูุง)
- **xโ, xโ, ...**: ุงููุชุบูุฑุงุช ุงููุณุชููุฉ (ุงูุนูุฑุ ุงูุฑุงุชุจุ ุฅูุฎ)
- **wโ, wโ, ...**: ุงูุฃูุฒุงู (ูุฏู ุชุฃุซูุฑ ูู ูุชุบูุฑ)
- **b**: ุงูุงูุญูุงุฒ (bias)

### ูุซุงู ุจุณูุท

ุชุฎูู ุฃููุง ูุฑูุฏ ุงูุชูุจุค ุจุฑุบุจุฉ ุงูุนููู ูู ุงููุฑุถ ุจูุงุกู ุนูู ุงูุฑุงุชุจ ููุท:

```
y = 0.5 * salary + 10

ูุซุงู:
- ุฅุฐุง ูุงู ุงูุฑุงุชุจ 50,000 โ y = 0.5ร50000 + 10 = 25010 (ุงุญุชูุงููุฉ ุนุงููุฉ)
- ุฅุฐุง ูุงู ุงูุฑุงุชุจ 20,000 โ y = 0.5ร20000 + 10 = 10010 (ุงุญุชูุงููุฉ ููุฎูุถุฉ)
```

### ููู ูุนููุ

```
ุงูุฎุทูุฉ 1: ุงูุชููุฆุฉ ุงูุนุดูุงุฆูุฉ
wโ = 0.1, wโ = 0.05, ..., b = 0.2

ุงูุฎุทูุฉ 2: ุงูุชูุจุค ุนูู ุจูุงูุงุช ุงูุชุฏุฑูุจ
y_pred = X_train * w + b

ุงูุฎุทูุฉ 3: ุญุณุงุจ ุงูุฎุทุฃ
error = (y_true - y_pred)ยฒ

ุงูุฎุทูุฉ 4: ุชุญุฏูุซ ุงูุฃูุฒุงู ูุชูููู ุงูุฎุทุฃ
w = w - learning_rate ร gradient

ุงูุฎุทูุฉ 5: ุชูุฑุงุฑ ุงูุฎุทูุงุช 2-4 ุญุชู ุงูุชูุงุฑุจ
```

### ุงููููุฒุงุช ูุงูุนููุจ

โ **ุงููููุฒุงุช:**
- ูููุฐุฌ ุจุณูุท ูุณุฑูุน
- ุณูู ุงูููู ูุงูุชูุณูุฑ
- ูุนูู ุฌูุฏุงู ูุน ุงูุจูุงูุงุช ุงูุฎุทูุฉ

โ **ุงูุนููุจ:**
- ููุชุฑุถ ุนูุงูุฉ ุฎุทูุฉ (ูุฏ ูุง ุชููู ุตุญูุญุฉ ุฏุงุฆูุงู)
- ุญุณุงุณ ููููู ุงูุดุงุฐุฉ (Outliers)

### ูู ูุดุฑูุนูุง

```python
from sklearn.linear_model import LinearRegression

# ุฅูุดุงุก ุงููููุฐุฌ
lr = LinearRegression()

# ุงูุชุฏุฑูุจ
lr.fit(X_train, y_train)

# ุงูุชูุจุค
y_pred = lr.predict(X_test)

# ุงููุชุงุฆุฌ:
# MSE: 0.0550
# RMSE: 0.2345
# Accuracy: 92.13%
# AUC: 0.9671
```

---

## ๐ค KNN Regression

### ูุง ูู KNNุ

**K-Nearest Neighbors** = "ุฃูุฑุจ K ุฌุงุฑ"

ููุฑุฉ ุจุณูุทุฉ ุฌุฏุงู: ุนูุฏูุง ุชุฑูุฏ ุงูุชูุจุค ุจูููุฉ ุฌุฏูุฏุฉุ ุงุจุญุซ ุนู ุฃูุฑุจ K ููุทุฉ ูู ุจูุงูุงุช ุงูุชุฏุฑูุจ ูุฎุฐ ูุชูุณุท ููููู.

### ูุซุงู ุนููู

ุชุฎูู ุฃู ูุฏูู ุฎุฑูุทุฉ ุจูุง ููุงุท ุชูุซู ุนููุงุก (ุฃุญูุฑ = ูุจู ุงููุฑุถุ ุฃุฒุฑู = ุฑูุถ ุงููุฑุถ)

```
ุนููุงุก ุณุงุจููู:
โโโโ ุนููู ุฌุฏูุฏ    โ ูุฑูุฏ ูุนุฑูุฉ ูููู

ุฅุฐุง ุงุฎุชุจุฑูุง k=3:
- ุฃูุฑุจ 3 ููุงุท ุญูู ุงูุนููู ุงูุฌุฏูุฏ
- ูุนุฏ ุงูุฃููุงู: ุฃุญูุฑ: 2ุ ุฃุฒุฑู: 1
- ุงูุฃูุซุฑูุฉ = ุฃุญูุฑ โ ูุชูุจุฃ ุฃูู ุณููุจู ุงููุฑุถ

ุฅุฐุง ุงุฎุชุจุฑูุง k=5:
- ุฃูุฑุจ 5 ููุงุท ุญูู ุงูุนููู ุงูุฌุฏูุฏ
- ูุนุฏ ุงูุฃููุงู: ุฃุญูุฑ: 3ุ ุฃุฒุฑู: 2
- ุงูุฃูุซุฑูุฉ = ุฃุญูุฑ โ ูุชูุจุฃ ุฃูู ุณููุจู ุงููุฑุถ
```

### ุงููุฑู ุจูู KNN ููุชุตููู ูุงูุงูุญุฏุงุฑ

| KNN Classification | KNN Regression |
|-------------------|----------------|
| ุชุตููุช ุจุงูุฃุบูุจูุฉ | ูุชูุณุท ุงูููู |
| ุงููุชูุฌุฉ: ูุฆุฉ | ุงููุชูุฌุฉ: ุฑูู |
| ูุซุงู: (ูุนู/ูุง) | ูุซุงู: ุงุญุชูุงููุฉ (0-1) |

### ููู ุชุฎุชุงุฑ kุ

```
k=1:
- Pro: ุณุฑูุน ุฌุฏุงู
- Con: ูุชุฃุซุฑ ุจุงูุถูุถุงุก

k=3:
- Pro/Con: ุชูุงุฒู

k=10:
- Pro: ุฃูู ุชุฃุซุฑุงู ุจุงูุถูุถุงุก
- Con: ูุฏ ูููุฏ ุงูุชูุงุตูู ุงูุฏูููุฉ
```

### GridSearchCV: ุงูุนุซูุฑ ุนูู ุฃูุถู k

```python
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsRegressor

# ุฌุฑุจ k ูู 1 ุฅูู 20
param_grid = {"n_neighbors": list(range(1, 21))}

knn = GridSearchCV(
    KNeighborsRegressor(),
    param_grid,
    cv=5,  # 5-fold cross-validation
    scoring="neg_mean_squared_error"
)

knn.fit(X_train, y_train)
print("ุฃูุถู k:", knn.best_params_)  # ุฃูุถู k = 5
```

### ุงููุชุงุฆุฌ ูู ูุดุฑูุนูุง

```
KNN (k=5):
- MSE: 0.0386 (ุฃูุถู ูู Linear!)
- RMSE: 0.1965 (ุฃูุถู ูู Linear!)
- Accuracy: 94.80% (ุฃูุถู ูู Linear!)
- AUC: 0.9496
```

---

## ๐ Learning Curve

### ูุง ููุ

ููุญูู ุงูุชุนูู ููุถุญ ููู ูุชุญุณู ุงููููุฐุฌ ูุน ุฒูุงุฏุฉ ุญุฌู ุจูุงูุงุช ุงูุชุฏุฑูุจ.

### ุงูููุฑุฉ

```
ุงูุณุคุงู: ูู ูููุฐุฌูุง ูุชุนูู ููุท ูู ุงูุจูุงูุงุช ุงูุญุงููุฉ ุฃู ุฃูู ุณูุณุชูุฑ ูุชุญุณู ูุน ุจูุงูุงุช ุฃูุซุฑุ

ุงูุฅุฌุงุจุฉ: ูุฎุชุจุฑ ุจุฃุญุฌุงู ูุฎุชููุฉ ูู ุงูุจูุงูุงุช
```

### ููู ุชุตูุน Learning Curveุ

```python
import numpy as np

fractions = [0.1, 0.2, 0.3, ..., 1.0]  # 10% ุฅูู 100% ูู ุงูุจูุงูุงุช
train_errors = []
val_errors = []

ููู ูุณุจุฉ:
    - ุฎุฐ ูุฐู ุงููุณุจุฉ ูู ุจูุงูุงุช ุงูุชุฏุฑูุจ
    - ุฏุฑูุจ ุงููููุฐุฌ
    - ุงุญุณุจ ุงูุฎุทุฃ ุนูู ุงูุชุฏุฑูุจ
    - ุงุญุณุจ ุงูุฎุทุฃ ุนูู ุงูุชุญูู
```

### ูุซุงู ุนููู

```
ุงุณุชุฎุฏุงู 10% ูู ุงูุจูุงูุงุช:
  ุฎุทุฃ ุงูุชุฏุฑูุจ: 0.15
  ุฎุทุฃ ุงูุชุญูู: 0.18

ุงุณุชุฎุฏุงู 30% ูู ุงูุจูุงูุงุช:
  ุฎุทุฃ ุงูุชุฏุฑูุจ: 0.12
  ุฎุทุฃ ุงูุชุญูู: 0.14

ุงุณุชุฎุฏุงู 70% ูู ุงูุจูุงูุงุช:
  ุฎุทุฃ ุงูุชุฏุฑูุจ: 0.08
  ุฎุทุฃ ุงูุชุญูู: 0.09

ุงุณุชุฎุฏุงู 100% ูู ุงูุจูุงูุงุช:
  ุฎุทุฃ ุงูุชุฏุฑูุจ: 0.055
  ุฎุทุฃ ุงูุชุญูู: 0.065
```

### ุงูุฑุณู ุงูุจูุงูู

```
ุงูุฎุทุฃ
  โฒ
  โ     ุชุญูู (Val)
  โ      โฑโฒ___
  โ     โฑ     \___
  โ____โฑ__________\___
  โ   ุชุฏุฑูุจ (Train)
  โโโโโโโโโโโโโโโโโโโโโโโบ ุนุฏุฏ ุงูุนููุงุช
     10%  30%  70% 100%
```

### ุฃููุงุน ุงูุฃููุงุท

#### 1๏ธโฃ ูููุฐุฌ ุฌูุฏ
```
โญโโโ Val (ุชุญูู)
โโโ ุงูุงุซูุงู ูุชูุงุฑุจุงู ูุงูุฎุทุฃ ููุฎูุถ
โโโโ Train (ุชุฏุฑูุจ)
โโโโ ูุดูุฑ ุฅูู ุชุนูู ุฌูุฏ
```

#### 2๏ธโฃ Underfitting (ูููุฐุฌ ุจุณูุท ุฌุฏุงู)
```
โโ Val ูTrain ููุงููุง ุนุงูู ุฌุฏุงู
โโ ุงููุณุงูุฉ ุจููููุง ุตุบูุฑุฉ
โโ ุงููููุฐุฌ ุจุณูุท ุฌุฏุงู ูููุดููุฉ
```

#### 3๏ธโฃ Overfitting (ูููุฐุฌ ูุนูุฏ ุฌุฏุงู)
```
โโ Train ููุฎูุถ ุฌุฏุงู
โโ Val ุนุงูู ุฌุฏุงู
โโ ุงููููุฐุฌ ูุญูุธ ุงูุจูุงูุงุช ุจุฏูุงู ูู ุงูุชุนูู ุงูุญูููู
```

### ูู ูุดุฑูุนูุง

```
ุงูุฑุณู ููุถุญ:
- ุฎุทุฃ ุงูุชุฏุฑูุจ ููุฎูุถ ุชุฏุฑูุฌูุงู
- ุฎุทุฃ ุงูุชุญูู ููุฎูุถ ุฃูุถุงู
- ุงููุฌูุฉ ุจููููุง ุตุบูุฑุฉ
โ ุงููููุฐุฌ ูุชุนูู ุจุดูู ุตุญูุญ!
```

---

## ๐ Validation Curve

### ูุง ุงููุฑู ูุน Learning Curveุ

| Learning Curve | Validation Curve |
|---|---|
| ูุบูุฑ: ุญุฌู ุงูุจูุงูุงุช | ูุบูุฑ: ูุนุงูู ููู ูู ุงููููุฐุฌ |
| ูุฎุชุจุฑ: ุงูุชุนูู | ูุฎุชุจุฑ: ุงูุชูุงุณุจ ุงูุฃูุซู |
| ุงูุณุคุงู: ูู ูุญุชุงุฌ ุจูุงูุงุช ุฃูุซุฑุ | ุงูุณุคุงู: ูุง ุฃูุถู ูููุฉ ูููุนุงููุ |

### ูุซุงู: KNN Validation Curve

```
ุงูุณุคุงู: ูุง ูู ุฃูุถู ูููุฉ kุ
ุงูุฅุฌุงุจุฉ: ูุฎุชุจุฑ k = 1, 2, 3, ..., 20
```

### ุงูุฑุณู ุงูุจูุงูู

```
ุงูุฎุทุฃ
  โ
  โ โฑโโโโโโโ Val (k ุบูุฑ ููุงุณุจ ูุจูุฑ)
  โโฑ
  โ          โฒ
  โ           โฒ  (k ููุงุณุจ)
  โ            โฒ___
  โ                 โฒ (k ุตุบูุฑ ุฌุฏุงู)
  โโโโโโโโโโโโโโโโโโโโโโโโบ k (ุนุฏุฏ ุงูุฌูุฑุงู)
     1  3  5  7  9  11
```

### ุงูุชูุณูุฑ

**k=1:** 
- ูุญูุธ ุงูุจูุงูุงุช ุชูุงูุงู
- overfitting

**k=5:** (ุงูุฃูุถู ูู ูุดุฑูุนูุง)
- ุชูุงุฒู ุฌูุฏ

**k=20:**
- ูุตุจุญ ุงููููุฐุฌ ุณูุณ ุฌุฏุงู
- underfitting

---

## ๐ฒ Confusion Matrix

### ูุง ููุ

ุฌุฏูู ููุถุญ ุงููุฑู ุจูู ูุง ุชููุนู ุงููููุฐุฌ ููุง ุญุฏุซ ูุนูุงู.

### ุงูุดูู ุงูุฃุณุงุณู

```
                  ุงููุงูุน
                ููุจู    ูุฑูุถ
        ููุจู    TP      FP
ุงูุชูุจุค
        ูุฑูุถ    FN      TN


ุงูุชูุงุตูู:
- TP (True Positive): ุชููุนูุง ูุนู ููุนูุงู ูุงู ูุนู โ
- TN (True Negative): ุชููุนูุง ูุง ููุนูุงู ูุงู ูุง โ
- FP (False Positive): ุชููุนูุง ูุนู ููู ูุงู ูุง โ
- FN (False Negative): ุชููุนูุง ูุง ููู ูุงู ูุนู โ
```

### ูุซุงู ุนููู

ุชุฎูู ุฃู ูุฏููุง 10 ุนููุงุก ุงุฎุชุจุฑูุง ุนูููู ุงููููุฐุฌ:

```
ุงููุงูุน:    [ูุนู, ูุนู, ูุง, ูุนู, ูุง, ูุนู, ูุง, ูุนู, ูุนู, ูุง]
ุงูุชูุจุค:    [ูุนู, ูุนู, ูุนู, ูุนู, ูุง, ูุง, ูุง, ูุนู, ูุนู, ูุนู]

ุงููุชูุฌุฉ:
- ุนุฏุฏ 1 (ูุนู, ูุนู): โ TP = 1
- ุนุฏุฏ 2 (ูุนู, ูุนู): โ TP = 2
- ุนุฏุฏ 3 (ูุง, ูุนู): โ FP = 1
- ุนุฏุฏ 4 (ูุนู, ูุนู): โ TP = 3
- ุนุฏุฏ 5 (ูุง, ูุง): โ TN = 1
- ุนุฏุฏ 6 (ูุนู, ูุง): โ FN = 1
- ุนุฏุฏ 7 (ูุง, ูุง): โ TN = 2
- ุนุฏุฏ 8 (ูุนู, ูุนู): โ TP = 4
- ุนุฏุฏ 9 (ูุนู, ูุนู): โ TP = 5
- ุนุฏุฏ 10 (ูุง, ูุนู): โ FP = 2

ูุตูููุฉ ุงูุงูุชุจุงุณ:
           ููุจู  ูุฑูุถ
ููุจู        5     2
ูุฑูุถ        1     2
```

### ุงูุตูุบุฉ ุงูุฌุฏูููุฉ

```
                 Predicted
                ููุจู   ูุฑูุถ
        ููุจู      5      1     (6 ุนููู ููุจู ูุนูุงู)
Actual
        ูุฑูุถ      2      2     (4 ุนููุงุก ูุฑูุถูู ูุนูุงู)
```

### ุงูุฑุณู ุงูุจูุงูู (Heatmap)

```python
import matplotlib.pyplot as plt

plt.imshow(cm, cmap="Blues")  # ุฃุฒุฑู ูุงุชุญ = ุฃููุ ุฃุฒุฑู ุบุงูู = ุฃูุซุฑ
plt.title("Confusion Matrix")

# ุงููุงุชุฌ:
โโโโโโโโโโโโโโโฆโโโโโโโโโโฆโโโโโโโโโโ
โ   Colors    โ ููุจู   โ ูุฑูุถ   โ
โโโโโโโโโโโโโโโฌโโโโโโโโโโฌโโโโโโโโโโฃ
โ ููุจู        โ 5 ๐ฆ๐ฆ โ 1 ๐ฆ   โ
โ ูุฑูุถ        โ 2 ๐ฆ   โ 2 ๐ฆ   โ
โโโโโโโโโโโโโโโฉโโโโโโโโโโฉโโโโโโโโโโ
```

### ุงูููุงุฆุฏ

โ ูุฑู ุงูุฃุฎุทุงุก ุจุงูุชูุตูู
โ ูููู ููุท ุงูุฃุฎุทุงุก
โ ูุญุณู ุงููููุฐุฌ ุจูุงุกู ุนูู ุงูุฃุฎุทุงุก

---

## ๐ ROC Curve ู AUC

### ูุง ูู ROC Curveุ

**ROC** = Receiver Operating Characteristic

ููุญูู ููุถุญ ุงูุนูุงูุฉ ุจูู:
- **TPR** (True Positive Rate): ุงูุญุงูุงุช ุงูููุฌุจุฉ ุงูุชู ุนุซุฑูุง ุนูููุง
- **FPR** (False Positive Rate): ุงูุญุงูุงุช ุงูุณุงูุจุฉ ุงูุชู ุชููุนูุงูุง ุฎุทุฃ

### ุงูุตูุบ

```
TPR = TP / (TP + FN)     ูู ูุณุจุฉ ุงูููุฌุจ ุงูุฐู ุนุซุฑูุง ุนูููุ
FPR = FP / (FP + TN)     ูู ูุณุจุฉ ุฎุทุฆูุง ูู ุงูุณุงูุจุ
```

### ุงูููุฑุฉ ุงูุฃุณุงุณูุฉ

```
ุงูุณุคุงู: ุฅุฐุง ุบูุฑูุง threshold (ุงูุนุชุจุฉ)ุ ููู ูุชุบูุฑ ุงูุฃุฏุงุกุ

ูุซุงู: ูููุฐุฌ ูุนุทููุง ุงุญุชูุงููุฉ (0-1)
- ุฅุฐุง ุงุญุชูุงููุฉ > 0.5 โ ุชููุน ูุนู
- ุฅุฐุง ุงุญุชูุงููุฉ โค 0.5 โ ุชููุน ูุง

ููู ูุงุฐุง ูู ุบูุฑูุง 0.5ุ
- ุฅุฐุง ุงุญุชูุงููุฉ > 0.3 โ ุชููุน ูุนู
- ุฅุฐุง ุงุญุชูุงููุฉ > 0.7 โ ุชููุน ูุนู
```

### ุงูุฑุณู ุงูุจูุงูู

```
TPR (ุงูุญุณุงุณูุฉ)
  โฒ
  โ     โฑโโ ุงููููุฐุฌ ุงูููุชุงุฒ
  โ    โฑ
  โ   โฑโโ ุงููููุฐุฌ ุงูุฌูุฏ
  โ  โฑโฒ
  โ โฑ  โฒโโโโโ ุงููููุฐุฌ ุงูุณูุก
  โโฑ      โฒ (ุฎุท ุนุดูุงุฆู)
  โโโโโโโโโโโโโโโโโโบ FPR (1-ุงูุฎุตูุตูุฉ)
     0         1
```

### AUC: Area Under Curve

ุงููุณุงุญุฉ ุชุญุช ุงูููุญูู

```
AUC = 1.0: ูููุฐุฌ ูุซุงูู (ูู ุงูุชูุจุคุงุช ุตุญูุญุฉ)
AUC = 0.9: ูููุฐุฌ ููุชุงุฒ
AUC = 0.8: ูููุฐุฌ ุฌูุฏ ุฌุฏุงู
AUC = 0.7: ูููุฐุฌ ุฌูุฏ
AUC = 0.5: ูููุฐุฌ ุนุดูุงุฆู (ูุง ูุงุฆุฏุฉ)
```

### ูู ูุดุฑูุนูุง

```
Linear Regression:
- AUC = 0.9671 ููุชุงุฒ ุฌุฏุงู! (96.71%)

KNN:
- AUC = 0.9496 ููุชุงุฒ ุฃูุถุงู! (94.96%)
```

### ุงูุชูุณูุฑ ุงูุนููู

```
AUC = 0.9671 ูุนูู:

ุฅุฐุง ุฃุฎุฐูุง ุนููู ุนุดูุงุฆู ููุจู ุงููุฑุถ ูุนููู ุนุดูุงุฆู ูุฑูุถูุ
ุงููููุฐุฌ ูุฏูู ุงุญุชูุงููุฉ 96.71% ุฃู ูุนุทู ุงููููุฐุฌ ุงุญุชูุงููุฉ
ุฃุนูู ููุนููู ุงูุฐู ููุจู ููุงุจู ุงูุฐู ูุฑูุถ.
```

---

## ๐ Accuracy

### ูุง ููุ

ุงููุณุจุฉ ุงููุฆููุฉ ููุชูุจุคุงุช ุงูุตุญูุญุฉ ูู ุฅุฌูุงูู ุงูุชูุจุคุงุช.

### ุงูุตูุบุฉ

```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
         = ุนุฏุฏ ุงูุชูุจุคุงุช ุงูุตุญูุญุฉ / ุฅุฌูุงูู ุงูุชูุจุคุงุช
```

### ูุซุงู

ูู ูุซุงููุง ุงูุณุงุจู:

```
TP = 5 (ุตุญูุญ ููุฌุจ)
TN = 2 (ุตุญูุญ ุณุงูุจ)
FP = 2 (ุฎุทุฃ ููุฌุจ)
FN = 1 (ุฎุทุฃ ุณุงูุจ)

Accuracy = (5 + 2) / (5 + 2 + 2 + 1)
         = 7 / 10
         = 0.7
         = 70%
```

### ูุซุงู ูู ูุดุฑูุนูุง

```
ูู ูุฌููุนุฉ ุงูุงุฎุชุจุงุฑ:
- ูุฏููุง 750 ุนููู
- ุงููููุฐุฌ ุชูุจุฃ ุจู 750 ูุฑุฉ
- ูู ูุฐู 689 ูุฑุฉ ูุงู ุงูุชูุจุค ุตุญูุญ

Accuracy = 689 / 750 = 91.87% (Linear Regression)
Accuracy = 711 / 750 = 94.80% (KNN)
```

### ูุชู ุชููู ูููุฏุฉุ

โ **ุงุณุชุฎุฏู Accuracy ุนูุฏูุง:**
- ุงููุฆุงุช ูุชูุงุฒูุฉ
- ูู ุงูุฃุฎุทุงุก ูุชุณุงููุฉ ุงูุชูููุฉ

โ **ูุง ุชุณุชุฎุฏู Accuracy ุนูุฏูุง:**
- ุงูุจูุงูุงุช ุบูุฑ ูุชูุงุฒูุฉ
  - ูุซุงู: 95% ููุฌุจุ 5% ุณุงูุจ
  - ูููู ุงููููุฐุฌ ุฃู ูููู ุฏููู 95% ุจุงูููู ุฏุงุฆูุงู "ููุฌุจ"!

### ูุซุงู ุงููุดููุฉ

```
ุจูุงูุงุช ุบูุฑ ูุชูุงุฒูุฉ (95% ููุฌุจุ 5% ุณุงูุจ):

ุงููููุฐุฌ ุงูุบุจู: ูููู ุฏุงุฆูุงู "ููุฌุจ"
Accuracy = 95% (ูุจุฏู ุฌูุฏุงู!)

ููู ุงููููุฐุฌ ูู ูุชุนูู ุดูุก!
ูู ุงููุงูุนุ ูุง ูุณุชุทูุน ุงูุชุดุงู ุงูุณุงูุจ (0% recall for negative)
```

---

## ๐ ููุงุฑูุฉ ุงูููุงุฐุฌ

### ุฌุฏูู ุงููุชุงุฆุฌ ุงููุงูู

| ุงููููุงุณ | Linear Regression | KNN (k=5) | ุงูุฃูุถู |
|-------|---|---|---|
| **MSE** | 0.0550 | 0.0386 | KNN โ |
| **RMSE** | 0.2345 | 0.1965 | KNN โ |
| **Accuracy** | 92.13% | 94.80% | KNN โ |
| **AUC** | 0.9671 | 0.9496 | Linear โ |

### ุงูุชุญููู

```
โ KNN ุฃูุถู ูู:
   - ุงูุฎุทุฃ ุงูุชุฑุจูุนู (MSE ู RMSE)
   - ุงูุฏูุฉ ุงููููุฉ (Accuracy)

โ Linear Regression ุฃูุถู ูู:
   - AUC (ุงููุฏุฑุฉ ุนูู ุงูุชูููุฒ)

๐ฏ ุงูุฎูุงุฑ ุงูุฃูุถู: KNN
   - ูููุฒ ูู ุฃูุซุฑ ุงูููุงููุณ
   - ุงููุฑู ูู AUC ููุณ ูุจูุฑุงู
```

### ููุงุฐุง KNN ุฃูุถู ููุงุ

```
1๏ธโฃ ุงูุจูุงูุงุช ูุฏ ุชุญุชูู ุนูู ุฃููุงุท ุบูุฑ ุฎุทูุฉ
   - KNN ููููู ุงูุชุดุงู ุฃููุงุท ูุนูุฏุฉ

2๏ธโฃ ุงูุจูุงูุงุช ูุชูุงุฑุจุฉ ูุญููุงู
   - ุงูุนููุงุก ุงููุชุดุงุจููู ููู ูุฑุงุฑุงุช ูุชุดุงุจูุฉ
   - KNN ูุณุชููุฏ ูู ูุฐู ุงูุฎุงุตูุฉ

3๏ธโฃ ุงูุฃูุฒุงู ุชู ูุนุงูุฑุชูุง ุฌูุฏุงู
   - StandardScaler ูุจู KNN ุณุงุนุฏ ูุซูุฑุงู
```

---

## ๐ฏ ุฃุณุฆูุฉ ุดุงุฆุนุฉ

### ุณ: ุงูู ุงููุฑู ุจูู MSE ู Accuracyุ

```
MSE = ูููุงุณ ููุฎุทุฃ ุงููุนูู (ุฑูู ุฏููู)
      ูููู ุฃู ูููู 0.0550

Accuracy = ูุณุจุฉ ุงูุชูุจุคุงุช ุงูุตุญูุญุฉ (ูุณุจุฉ ูุฆููุฉ)
          ุชููู 92.13%

MSE ูุฎุจุฑู: ูู ุงููุณุงูุฉ ุจูู ุงูุชูุจุค ูุงููุงูุนุ
Accuracy ูุฎุจุฑู: ูู ูุฑุฉ ููุช ูุญูุ
```

### ุณ: ููุงุฐุง ูุง ูุณุชุฎุฏู Accuracy ูุญุฏูุ

```
ูุซุงู ูุฑุถู: 99 ูุฑูุถ ุณูููุ 1 ูุฑูุถ ูุตุงุจ

ูููุฐุฌ ุบุจู: ูููู ุฏุงุฆูุงู "ุณููู"
Accuracy = 99% (ุฌูุฏ ุนูู ุงููุฑู!)

ููู ุงูุญูููุฉ:
- ูุดู ูู ุงูุชุดุงู ุงููุฑูุถ ุงููุตุงุจ
- ูู ุงูุทุจุ ูุฐุง ูุงุฑุซุฉ!

ุงูุญู: ุงุณุชุฎุฏู AUC ู Sensitivity ู Specificity
```

### ุณ: ูุชู ุฃุณุชุฎุฏู Learning Curveุ

```
ุงุณุชุฎุฏู Learning Curve ุนูุฏูุง:
- ุชุฑูุฏ ุฃู ุชูุฑุฑ: ูู ูุญุชุงุฌ ุจูุงูุงุช ุฃูุซุฑุ
- ุชุฑูุฏ ุฃู ุชููู: ูู ุงููููุฐุฌ ูุชุนูู ุจุดูู ุตุญูุญุ
- ุชุฑูุฏ ุฃู ุชูุชุดู: ูู ุนูุฏู overfittingุ
```

### ุณ: ูุชู ุฃุณุชุฎุฏู Validation Curveุ

```
ุงุณุชุฎุฏู Validation Curve ุนูุฏูุง:
- ุนูุฏู ูุนุงูู ูููู ุชุบููุฑู (ูุซู k ูู KNN)
- ุชุฑูุฏ ุฃู ุชุฌุฏ: ุงููููุฉ ุงููุซูู ููุฐุง ุงููุนุงูู
- ุชุฑูุฏ ุฃู ุชููู: ุชุฃุซูุฑ ูุฐุง ุงููุนุงูู ุนูู ุงูุฃุฏุงุก
```

---

## ๐ ุงูุฎูุงุตุฉ

| ุงูููููู | ุงูุบุฑุถ | ุงูุฅุฌุงุจุฉ ุนูู |
|---|---|---|
| **Linear Regression** | ูููุฐุฌ ุจุณูุท | ุนูุงูุฉ ุฎุทูุฉุ |
| **KNN** | ูููุฐุฌ ูุนุชูุฏ ุนูู ุงูุชุดุงุจู | ูุง ุฃูุฑุจ ุงูุฃูุซูุฉุ |
| **Learning Curve** | ููู ุณููู ุงููููุฐุฌ | ูู ูุญุชุงุฌ ุจูุงูุงุช ุฃูุซุฑุ |
| **Validation Curve** | ุงุฎุชูุงุฑ ุงููุนุงููุงุช ุงููุซูู | ูุง ุฃูุถู kุ |
| **Confusion Matrix** | ููู ุงูุฃุฎุทุงุก ุจุงูุชูุตูู | ุฃูู ูุฎุทุฆ ุงููููุฐุฌุ |
| **ROC Curve** | ููุงุณ ุงููุฏุฑุฉ ุนูู ุงูุชูููุฒ | ูุง ุฌูุฏุฉ ุงููุตูุ |
| **AUC** | ุฑูู ูุงุญุฏ ููุฃุฏุงุก | ูุง ุงุญุชูุงููุฉ ุงูุตุญุฉุ |
| **Accuracy** | ุงููุณุจุฉ ุงููุฆููุฉ ุงููููุฉ | ูู ูุณุจุฉ ุงูุตุญุฉุ |

---

**ุขุฎุฑ ุชุญุฏูุซ:** ุฏูุณูุจุฑ 2025
